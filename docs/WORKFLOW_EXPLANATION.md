# Lead Scoring Agent - Workflow Explanation

## What Does This Agent Do?

Imagine you're a sales team drowning in hundreds of potential customers (leads). You don't know which ones are actually interested in buying. This agent is like a **smart assistant that predicts which leads are most likely to become customers**, so your sales team can focus on the right people.

---

## The Core Workflow (6 Steps)

### 1ï¸âƒ£ **VALIDATE** - Check the Input
```
Lead comes in â†’ Agent checks: "Does this lead have all the info I need?"
- Age, location, industry?
- Email opens, website visits?
- Source (webinar, referral, etc.)?

âœ… Valid? â†’ Move to next step
âŒ Invalid? â†’ Return error
```

### 2ï¸âƒ£ **PREPROCESS** - Prepare the Data
```
Raw lead data â†’ Transform it into features the ML model understands
- Age: 35 â†’ normalized value
- Location: "New York" â†’ encoded number
- Engagement metrics â†’ calculated intensity scores

Think of it like translating languages so the AI can "read" the lead
```

### 3ï¸âƒ£ **SCORE** - Predict Conversion Probability
```
Prepared data â†’ ML Model (Logistic Regression) analyzes patterns

The model asks:
- "Does this lead look like past leads that converted?"
- "High email opens + Recent contact + Tech industry = Usually converts!"

Output: 0.78 (78% chance of converting)
```

### 4ï¸âƒ£ **STORE** - Save to Database
```
Lead score â†’ Saved to SQLite database

Stores:
- Lead ID: "LEAD-12345"
- Score: 0.78
- Risk Category: "high" (because 0.78 > 0.7)
- Timestamp, Model Version
- Actual Outcome (if provided as feedback)
```

### 5ï¸âƒ£ **LEARN** - Check if Retraining Needed
```
Agent counts feedback samples: "Do we have 50+ leads with actual outcomes?"

If YES (50+):
  â†’ Trigger background retraining (doesn't block response)
  â†’ "I'll learn from these outcomes and improve!"

If NO:
  â†’ "Not enough data yet, keep current model"
```

### 6ï¸âƒ£ **RESPOND** - Return the Answer
```
Format the result â†’ Send back to user

{
  "lead_id": "LEAD-12345",
  "conversion_score": 0.78,
  "risk_category": "high",
  "model_version": "1.0"
}

Sales team sees: "This is a HIGH priority lead! Call them NOW!"
```

---

## The Learning Loop (Adaptive Intelligence)

### How It Gets Smarter Over Time

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Score leads â†’ 2. Sales team contacts   â”‚
â”‚                                             â”‚
â”‚  6. Use new     â† 5. Model    â† 4. Retrain â”‚
â”‚     model          improves?     with data  â”‚
â”‚                                             â”‚
â”‚  3. Actual outcomes collected (converted or not)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Example:**
- **Day 1:** Agent scores LEAD-001 as 0.80 (high)
- **Week 1:** Sales team contacts them â†’ They convert! âœ…
- **Week 2:** Agent scores LEAD-002 as 0.75 (high)
- **Week 2:** Sales team contacts them â†’ They DON'T convert âŒ

**After 50+ outcomes collected:**
- Agent: "Wait! I thought 0.75 was good, but those leads didn't convert"
- Agent retrains itself on real data
- Agent: "I learned! Now I need 0.82+ to call it 'high risk'"
- **New model deployed automatically** (version 1.0 â†’ 1.1)

---

## Why This Matters

### Without Agent:
- Sales calls 100 leads randomly
- 10 convert (10% success rate)
- Wasted time on 90 uninterested people

### With Agent:
- Agent identifies top 20 leads (scored 0.7+)
- Sales calls only those 20 leads
- 10 convert (50% success rate!)
- **5x more efficient** - same conversions, 80% less effort

---

## The Smart Parts

### 1. **Feature Engineering** (Phase 2)
The agent doesn't just look at raw numbers. It creates **intelligent features**:

```
Raw Data:
- Email opens: 15
- Website visits: 10
- Days since contact: 7

Engineered Features:
- Engagement intensity = (15 + 10) / 7 = 3.57 interactions per day
- Recency weight = 1 / (1 + 7) = 0.125 (recent = better)
- Interaction frequency = 15 / (7 + 1) = 1.875 emails per day

The model sees these patterns: "High engagement + Recent contact = Strong lead!"
```

### 2. **Risk Categorization**
Simple color coding for sales teams:

```
Score 0.7 - 1.0  â†’ ğŸ”´ HIGH    â†’ "Call them TODAY!"
Score 0.4 - 0.7  â†’ ğŸŸ¡ MEDIUM  â†’ "Call them this week"
Score 0.0 - 0.4  â†’ ğŸŸ¢ LOW     â†’ "Send email follow-up"
```

### 3. **Automatic Retraining** (Phase 3)
The agent monitors itself:

```python
if feedback_count >= 50:
    new_model = train_with_feedback()
    
    if new_model.accuracy > old_model.accuracy + 2%:
        deploy(new_model)
        print("I'm smarter now! Version 1.1 deployed")
    else:
        print("Current model is still best, keeping it")
```

### 4. **Non-Blocking Learning**
The agent doesn't make you wait:

```
User: "Score this lead"
Agent: *Scoring in 2.3 seconds*
Agent: "Here's your score: 0.78"

[Behind the scenes, in background thread:]
Agent: "Oh, we have 50 feedback samples now..."
Agent: *Retraining model... 2 minutes...*
Agent: "New model ready! Deployed version 1.1"

User never waited - they got their score immediately!
```

---

## Real-World Example

**Monday Morning:**
```
â†’ LEAD-5001 enters system (came from webinar)
â†’ Agent: VALIDATE â†’ All fields present âœ“
â†’ Agent: PREPROCESS â†’ 37 features calculated
â†’ Agent: SCORE â†’ 0.87 (Model sees: Recent webinar + Tech industry + High engagement)
â†’ Agent: STORE â†’ Saved to database
â†’ Agent: LEARN â†’ "Only 49 feedback samples, need 1 more"
â†’ Agent: RESPOND â†’ "LEAD-5001: 87% conversion chance - HIGH PRIORITY"
â†’ Sales team calls immediately â†’ Sale closed! âœ…
```

**Tuesday Morning:**
```
â†’ Sales marks LEAD-5001 as "converted" (feedback)
â†’ Agent: "That's 50 feedback samples! Time to learn!"
â†’ Agent: *Retrains in background*
â†’ Agent: "New patterns found! Tech leads from webinars convert at 92%, not 87%"
â†’ Agent: "New model improves AUC from 0.9986 to 0.9992"
â†’ Agent: "Deploying version 1.1"
â†’ All future webinar leads scored more accurately
```

---

## The Technology Stack (Simplified)

1. **FastAPI** = The messenger (receives requests, sends responses)
2. **SQLite** = The notebook (remembers everything)
3. **Logistic Regression** = The brain (predicts conversion)
4. **LangGraph** = The workflow manager (orchestrates 6 steps)
5. **Pydantic** = The validator (checks data is correct)
6. **scikit-learn** = The learning toolkit (trains models)

---

## Key Metrics

- **AUC Score: 0.9986** â†’ Model is 99.86% accurate at ranking leads
- **Response Time: 2.3s** â†’ Fast enough for real-time use
- **Automatic Retraining** â†’ Gets smarter without human intervention
- **50+ Feedback Threshold** â†’ Waits for enough data before retraining

---

**In One Sentence:**  
This agent is a **self-improving AI assistant that predicts which sales leads will convert, learns from actual outcomes, and automatically gets smarter over time** - turning your sales team from randomly calling leads into laser-focused conversion machines.

---

## How Sales Team Provides Feedback for Retraining

### The Problem
For the agent to learn and improve, it needs to know: **"Did the lead we predicted actually convert or not?"**

### The Solution: `actual_outcome` Field

Sales teams provide feedback through the **same `/score` endpoint** using an optional field called `actual_outcome`.

---

### Step-by-Step Example

#### Initial Scoring (Week 1)
```json
POST /score
{
  "lead_id": "LEAD-5001",
  "age": 42,
  "location": "San Francisco",
  "industry": "Technology",
  "email_opens": 25,
  "website_visits": 18,
  "content_downloads": 8,
  "days_since_contact": 2,
  "lead_source": "Webinar",
  "actual_outcome": null  // â† Don't know yet
}

Response: {
  "conversion_score": 0.87,  // Agent predicts 87% chance
  "risk_category": "high"
}
```

**What happens:**
- Agent scores the lead: 87% likely to convert
- Sales team calls the lead
- Lead says: "I'm interested, let me think about it"
- We wait...

---

#### Feedback Provided (Week 3)
```json
POST /score
{
  "lead_id": "LEAD-5001",  // â† Same lead ID
  "age": 42,
  "location": "San Francisco",
  "industry": "Technology",
  "email_opens": 32,  // More engagement
  "website_visits": 25,
  "content_downloads": 12,
  "days_since_contact": 16,
  "lead_source": "Webinar",
  "actual_outcome": true  // â† âœ… They signed the contract!
}

Response: {
  "conversion_score": 0.91,
  "risk_category": "high"
}
```

**Behind the scenes:**
- Database stores: `actual_outcome = 1` (converted)
- Feedback counter: 48 â†’ 49
- Agent: "One more feedback sample to reach 50!"

---

### When Retraining Triggers

#### The 50th Feedback (Week 4)
```json
POST /score
{
  "lead_id": "LEAD-5002",
  "age": 35,
  "location": "Austin",
  "industry": "Healthcare",
  "email_opens": 10,
  "website_visits": 5,
  "content_downloads": 2,
  "days_since_contact": 45,
  "lead_source": "Cold Call",
  "actual_outcome": false  // â† âŒ Did not convert
}
```

**ğŸ”¥ Retraining Triggered:**
```
1. Feedback count reaches 50 âœ…
2. Background thread starts retraining (non-blocking)
3. Agent collects all 50 leads with actual outcomes
4. Trains new model on real data
5. Compares new model vs old model:
   - Old model AUC: 0.9986
   - New model AUC: 0.9992
   - Improvement: +0.0006 (0.06%)
6. Check: Is improvement â‰¥ 2%?
   - No â†’ Keep old model
   - Yes â†’ Deploy new model as version 1.1
```

**User experience:**
- Gets their score in 2.3 seconds (never waits for retraining!)
- Retraining happens silently in background

---

### What Gets Stored in Database

```sql
lead_scores table:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ lead_id      â”‚ age â”‚ location     â”‚ score        â”‚ actual_outcome â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LEAD-5001    â”‚ 42  â”‚ San Fran     â”‚ 0.87         â”‚ 1 (âœ… YES)     â”‚
â”‚ LEAD-5002    â”‚ 35  â”‚ Austin       â”‚ 0.25         â”‚ 0 (âŒ NO)      â”‚
â”‚ LEAD-5003    â”‚ 38  â”‚ New York     â”‚ 0.92         â”‚ NULL (unknown) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Values:**
- `NULL` = No feedback yet (lead still being worked)
- `1` = Converted âœ… (closed-won)
- `0` = Did not convert âŒ (closed-lost)

---

### Real-World Integration Options

#### Option 1: CRM Webhook (Automatic)
```python
# Salesforce/HubSpot triggers this when deal closes
when deal.status_changed:
    requests.post("http://lead-agent:8000/score", json={
        "lead_id": deal.lead_id,
        # ... all lead fields ...
        "actual_outcome": deal.is_won  # â† Automatic!
    })
```

#### Option 2: Weekly Batch Script
```python
# Run every Friday
closed_leads = crm.get_closed_leads_this_week()
for lead in closed_leads:
    update_agent_with_outcome(lead.id, lead.converted)
```

#### Option 3: Simple Web Form (Manual)
```html
<form action="/score" method="POST">
  <input name="lead_id" placeholder="LEAD-12345">
  <select name="actual_outcome">
    <option value="true">âœ… Converted</option>
    <option value="false">âŒ Lost</option>
  </select>
  <button>Submit Feedback</button>
</form>
```

---

### Why This Design is Brilliant

1. **Same Endpoint** â†’ No need to learn new API
2. **Optional Field** â†’ Works with or without feedback
3. **Automatic Counting** â†’ Agent tracks feedback samples
4. **Non-Blocking** â†’ Retraining doesn't slow down responses
5. **Smart Deployment** â†’ Only deploys if model actually improves
6. **Self-Improving** â†’ Gets smarter without manual intervention

---

### Monitoring Feedback Status

Check how many feedback samples collected:

```bash
GET /info

Response:
{
  "feedback_samples_collected": 52,
  "retraining_status": {
    "feedback_count": 52,
    "retraining_threshold": 50,
    "ready_for_retraining": true,
    "last_retrain_time": "2025-11-22T17:34:08"
  }
}
```

---

### The Learning Cycle Visualized

```
Week 1: Score 10 leads â†’ Sales calls them
Week 2: Score 20 more leads â†’ Sales calls them
Week 3: Score 20 more leads â†’ Sales calls them
        â†“
Week 4: 50 outcomes collected!
        â”œâ”€ 35 converted âœ…
        â”œâ”€ 15 did not convert âŒ
        â†“
Week 4: Agent retrains
        â”œâ”€ "Aha! I see patterns in the real data!"
        â”œâ”€ "Webinar leads convert 25% more than I thought"
        â”œâ”€ "Healthcare leads need 30+ email opens, not 20"
        â†“
Week 5: New model (v1.1) deployed
        â””â”€ Predictions now match reality better!
```

---

### Summary: The Feedback Loop

1. **Agent scores lead** â†’ Prediction: 0.87
2. **Sales team contacts** â†’ Follow up over weeks
3. **Outcome determined** â†’ âœ… Converted or âŒ Lost
4. **Feedback submitted** â†’ `actual_outcome: true/false`
5. **Agent counts** â†’ "50 samples reached!"
6. **Retraining triggered** â†’ Learns from real outcomes
7. **Model improves** â†’ Better predictions
8. **Cycle repeats** â†’ Continuous learning!

**The agent doesn't just predict - it learns from being wrong and gets better! ğŸ¯**
